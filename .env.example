# LLM
BASE_URL=
API_KEY=
MODEL=
LLM_SEMAPHORE=10

# VLM
VLM_BASE_URL=
VLM_API_KEY=
VLM_MODEL=
VLM_SEMAPHORE=10

# LLM for benchmark purpose, using LLM to judge the output
# You can use the same endpoint as the one used for OpenRAG
JUDGE_BASE_URL=
JUDGE_MODEL=
JUDGE_API_KEY=

# App
APP_PORT=8080 # this is the forwarded port
API_NUM_WORKERS=1 # Number of uvicorn workers for the FastAPI app
# ENABLE_RAY_SERVE=true # Use Ray Serve for the API instead of Uvicorn

# # VLLM
# VLLM_PORT=8000

# # Vector db VDB Milvus
# VDB_HOST=milvus
# VDB_PORT=19530
# VDB_CONNECTOR_NAME=milvus

# RETRIEVER
CONTEXTUAL_RETRIEVAL=true
RETRIEVER_TOP_K=20 # Number of documents to return before reranking

# EMBEDDER
EMBEDDER_MODEL_NAME=Qwen/Qwen3-Embedding-0.6B # or jinaai/jina-embeddings-v3 if you will
EMBEDDER_BASE_URL=http://vllm:8000/v1
EMBEDDER_API_KEY=EMPTY

# RERANKER
RERANKER_ENABLED=false
RERANKER_MODEL=Alibaba-NLP/gte-multilingual-reranker-base # or jinaai/jina-reranker-v2-base-multilingual or jinaai/jina-colbert-v2 if you want
# RERANKER_PORT=7997 # Port for the reranker service
# RERANKER_BASE_URL=http://reranker:7997 # you can uncomment this if you want to use a specific base URL for the reranker service. In that, comment out the reranker docker service in docker-compose.yaml
RERANKER_TOP_K=5 # Number of documents to return after reranking. upgrade to 8 for better results if your llm has a wider context window

# Prompts
PROMPTS_DIR=../prompts/example3_en # you ca

# Loaders
PDFLoader=MarkerLoader
XDG_CACHE_HOME=/app/model_weights
# If using MarkerLoader
MARKER_MAX_TASKS_PER_CHILD=100
MARKER_MAX_PROCESSES=10
MARKER_MIN_PROCESSES=1
# MARKER_POOL_SIZE=1 # Value au increment if you have a cluster of machines
MARKER_NUM_GPUS=0.01

# To enable API HTTP authentication via HTTPBearer
AUTH_TOKEN=sk-openrag-1234

# set to true if you want to deploy chainlit ui
WITH_CHAINLIT_UI=true

# Ray
RAY_DEDUP_LOGS=0
RAY_DASHBOARD_PORT=8265

RAY_NUM_GPUS=0.1
RAY_POOL_SIZE=1 # Number of serializer actor instances
RAY_MAX_TASKS_PER_WORKER=5 # Number of tasks per serializer instance
RAY_DASHBOARD_PORT=8265
RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1
RAY_task_retry_delay_ms=3000
RAY_ENABLE_UV_RUN_RUNTIME_ENV=0

# SAVE UPLOADED FILES
SAVE_UPLOADED_FILES=true # usefull for chainlit source viewing


## Variables to add to activate indexer-ui
# INDEXERUI_COMPOSE_FILE=extern/indexer-ui/docker-compose.yaml  # Required path to the docker-compose file
# INDEXERUI_PORT=8067                                             # Port to expose the Indexer UI (default is 3042)
# INDEXERUI_URL='http://X.X.X.X:INDEXERUI_PORT'                   # Base URL of the Indexer UI (required to prevent CORS issues)
# VITE_API_BASE_URL='http://X.X.X.X:APP_PORT'                     # Base URL of your FastAPI backend. Used by the frondend


## Specific to Ray cluster
# SHARED_ENV=/ray_mount/.env
# MODEL_WEIGHTS_VOLUME=/ray_mount/model_weights
# DATA_VOLUME=/ray_mount/data
# CONFIG_VOLUME=/ray_mount/.hydra_config
# DB_VOLUME=/ray_mount/db
# UV_LINK_MODE=copy
# UV_CACHE_DIR=/tmp/uv-cache 
# RAY_ADDRESS=ray://X.X.X.X:10001
# HEAD_NODE_IP=X.X.X.X

# # Chainlit UI authentication
# CHAINLIT_AUTH_SECRET=... # has to be generated with with this command: 'uv run chainlit create-secret' but a random value works too.
# CHAINLIT_USERNAME=OpenRAG
# CHAINLIT_PASSWORD=OpenRAG2025

# # For chainlit data (chat history, etc) persistency
# ## Persistency services (localstack + AWS (Deployed Locally))
# CHAINLIT_DATALAYER_COMPOSE=extern/chainlit-datalayer/compose.yaml


# ## PostgreSQL instance for data persistency.
# POSTGRES_USER=root
# POSTGRES_PASSWORD=root
# POSTGRES_DB=postgres
# POSTGRES_PORT=5432
# DATABASE_URL=postgresql://${POSTGRES_USER:-root}:${POSTGRES_PASSWORD:-root}@postgres:${POSTGRES_PORT:-5432}/${POSTGRES_DB:-postgres} # for chainlit

# ## S3 configuration (This is bucket deploy in deploy in a container).
# BUCKET_NAME=my-bucket
# APP_AWS_ACCESS_KEY=random-key
# APP_AWS_SECRET_KEY=random-key
# APP_AWS_REGION=eu-central-1
# LOCALSTACK_PORT=4566
# DEV_AWS_ENDPOINT=http://localstack:${LOCALSTACK_PORT:-4566}