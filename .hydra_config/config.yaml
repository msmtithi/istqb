defaults:
  - _self_  # TODO: Silences the hydra version migration warning (PLEASE REVIEW FOR BREAKING CHANGES)
  - chunker: recursive_splitter # markdown_splitter # semantic_splitter # 
  - retriever: single
  - rag: ChatBotRag

llm_params: &llm_params
  temperature: 0.1
  timeout: 60
  max_retries: 2
  logprobs: true

llm:
  <<: *llm_params
  base_url: ${oc.env:BASE_URL}
  model: ${oc.env:MODEL}
  api_key: ${oc.env:API_KEY}

vlm:
  <<: *llm_params
  base_url: ${oc.env:VLM_BASE_URL}
  model: ${oc.env:VLM_MODEL}  
  api_key: ${oc.env:VLM_API_KEY}

semaphore:
  llm_semaphore: ${oc.decode:${oc.env:LLM_SEMAPHORE, 10}}
  vlm_semaphore: ${oc.decode:${oc.env:VLM_SEMAPHORE, 10}}

embedder:
  type: huggingface
  model_name: ${oc.env:EMBEDDER_MODEL_NAME, jinaai/jina-embeddings-v3}
  base_url: ${oc.env:EMBEDDER_BASE_URL, http://vllm:8000/v1}
  api_key: ${oc.env:EMBEDDER_API_KEY, EMPTY}
  
vectordb:
  host: ${oc.env:VDB_HOST, milvus}
  port: ${oc.env:VDB_iPORT, 19530}
  connector_name: ${oc.env:VDB_CONNECTOR_NAME, milvus}
  collection_name: ${oc.env:VDB_COLLECTION_NAME, vdb_test} 
  hybrid_search: true
  enable: true

rdb:
  host: ${oc.env:POSTGRES_HOST, rdb}
  port: ${oc.env:POSTGRES_PORT, 5432}
  user: ${oc.env:POSTGRES_USER, root}
  password: ${oc.env:POSTGRES_PASSWORD, root_password}

reranker:
  enable: ${oc.decode:${oc.env:RERANKER_ENABLED, true}}
  model_name: ${oc.env:RERANKER_MODEL, Alibaba-NLP/gte-multilingual-reranker-base}
  top_k: ${oc.decode:${oc.env:RERANKER_TOP_K, 5}} # Number of documents to return after reranking. upgrade to 8 for better results if your llm has a wider context window
  base_url: ${oc.env:RERANKER_BASE_URL, http://reranker:${oc.env:RERANKER_PORT, 7997}}

map_reduce:
  map_reduce_n_docs: ${oc.decode:${oc.env:MAP_REDUCE_N_DOCS, 10}} # Number of documents to use in map-reduce

verbose:
  level: ${oc.env:LOG_LEVEL, DEBUG}

paths:
  prompts_dir: ${oc.env:PROMPTS_DIR, ../prompts/example1}
  data_dir: ${oc.env:DATA_DIR, ../data}
  db_dir: ${oc.env:DB_DIR, /app/db}
  log_dir: ${oc.env:LOG_DIR, /app/logs}

prompts:
  sys_prompt: sys_prompt_tmpl.txt
  query_contextualizer: query_contextualizer_tmpl.txt
  chunk_contextualizer: chunk_contextualizer_tmpl.txt
  image_describer: image_captioning_tmpl.txt

  # query templates for different retriever types
  hyde: hyde.txt
  multi_query: multi_query_pmpt_tmpl.txt

loader:
  image_captioning: true
  save_markdown: false
  audio_model: ${oc.env:WHISPER_MODEL, base} # tiny, base, small, medium, large-v1, large-v2, large-v3
  mimetypes:
    text/plain: .txt
    text/markdown: .md
    application/pdf: .pdf
    message/rfc822: .eml
    application/vnd.openxmlformats-officedocument.wordprocessingml.document: .docx
    application/vnd.openxmlformats-officedocument.presentationml.presentation: .pptx
    application/msword: .doc
    image/png: .png
    image/jpeg: .jpeg
    audio/vnd.wav: .wav
    audio/mpeg: .mp3
  file_loaders:
    txt: TextLoader
    pdf: ${oc.env:PDFLoader, MarkerLoader}  # DoclingLoader # MarkerLoader # PyMuPDFLoader # Custompymupdf4llm
    eml: EmlLoader
    docx: DocxLoader
    pptx: PPTXLoader
    doc: DocLoader
    png: ImageLoader
    jpeg: ImageLoader
    jpg: ImageLoader
    svg: ImageLoader
    wav: VideoAudioLoader
    mp3: VideoAudioLoader
    mp4: VideoAudioLoader
    ogg: VideoAudioLoader
    flv: VideoAudioLoader
    wma: VideoAudioLoader
    aac: VideoAudioLoader
    md: MarkdownLoader
  marker_max_tasks_per_child: ${oc.decode:${oc.env:MARKER_MAX_TASKS_PER_CHILD, 10}}
  marker_pool_size: ${oc.decode:${oc.env:MARKER_POOL_SIZE, 1}} # Value au increment if you have a cluster of machines
  marker_max_processes: ${oc.decode:${oc.env:MARKER_MAX_PROCESSES, 2}} # Maximum number of concurrent PDF parsing processes
  marker_min_processes: ${oc.decode:${oc.env:MARKER_MIN_PROCESSES, 1}}
  marker_num_gpus: ${oc.decode:${oc.env:MARKER_NUM_GPUS, 0.01}}
  marker_timeout: ${oc.decode:${oc.env:MARKER_TIMEOUT, 3600}}

ray:
  num_gpus: ${oc.decode:${oc.env:RAY_NUM_GPUS, 0.01}}
  pool_size: ${oc.decode:${oc.env:RAY_POOL_SIZE, 1}} # Number of serializer actor instances
  max_tasks_per_worker: ${oc.decode:${oc.env:RAY_MAX_TASKS_PER_WORKER, 8}} # Number of tasks per serializer instance
  indexer:
    max_task_retries: ${oc.decode:${oc.env:RAY_MAX_TASK_RETRIES, 2}}
    serialize_timeout: ${oc.decode:${oc.env:INDEXER_SERIALIZE_TIMEOUT, 36000}}
    concurrency_groups:
      default: ${oc.decode:${oc.env:INDEXER_DEFAULT_CONCURRENCY, 1000}}
      update: ${oc.decode:${oc.env:INDEXER_UPDATE_CONCURRENCY, 100}}
      search: ${oc.decode:${oc.env:INDEXER_SEARCH_CONCURRENCY, 100}}
      delete: ${oc.decode:${oc.env:INDEXER_DELETE_CONCURRENCY, 100}}
      chunk: ${oc.decode:${oc.env:INDEXER_CHUNK_CONCURRENCY, 1000}}
      insert: ${oc.decode:${oc.env:INDEXER_INSERT_CONCURRENCY, 10}}
  semaphore:
    concurrency: ${oc.decode:${oc.env:RAY_SEMAPHORE_CONCURRENCY, 100000}}
  serve:
    enable: ${oc.decode:${oc.env:ENABLE_RAY_SERVE, false}}
    num_replicas: ${oc.decode:${oc.env:RAY_SERVE_NUM_REPLICAS, 1}}
    host: ${oc.env:RAY_SERVE_HOST, 0.0.0.0}
    port: ${oc.env:RAY_SERVE_PORT, 8080}
